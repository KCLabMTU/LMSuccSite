{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb2738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-15 14:08:53.382520: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-06-15 14:08:53.386761: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-15 14:08:53.386775: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tqdm\n",
    "from Bio import SeqIO\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import keras functions\n",
    "# import tensorflow\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Input, Flatten, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# performance matrices\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score\n",
    "\n",
    "# plots\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Lambda, Embedding\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import backend as K\n",
    "from keras.backend import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l1, l2\n",
    "\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8c1a1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    # learning curves of model accuracy\n",
    "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.plot(history.history['loss'], label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b4b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_for_embedding(fasta_file):\n",
    "    encodings = []\n",
    "    \n",
    "    # define universe of possible input values\n",
    "    alphabet = 'ARNDCQEGHILKMFPSTWYV-'\n",
    "    \n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    \n",
    "    for seq_record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        data = seq_record.seq\n",
    "        for char in data:\n",
    "            if char not in alphabet:\n",
    "                return\n",
    "        integer_encoded = [char_to_int[char] for char in data]\n",
    "        encodings.append(integer_encoded)\n",
    "    encodings = np.array(encodings)\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f3b326e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sequences to integer encoding, for embedding\n",
    "test_positive_embedding = get_input_for_embedding('data/DeepSuccinylSite/fasta/test_positive_sites.fasta')\n",
    "test_negative_embedding = get_input_for_embedding('data/DeepSuccinylSite/fasta/test_negative_sites.fasta')\n",
    "train_positive_embedding = get_input_for_embedding('data/DeepSuccinylSite/fasta/positive_sites.fasta')\n",
    "train_negative_embedding = get_input_for_embedding('data/DeepSuccinylSite/fasta/negative_sites.fasta')\n",
    "\n",
    "# create labels\n",
    "train_positive_labels = np.ones(train_positive_embedding.shape[0])\n",
    "train_negative_labels = np.zeros(train_negative_embedding.shape[0])\n",
    "test_positive_labels = np.ones(test_positive_embedding.shape[0])\n",
    "test_negative_labels = np.zeros(test_negative_embedding.shape[0])\n",
    "\n",
    "# stack positive and negative data together\n",
    "X_train_full_embedding = np.vstack((train_positive_embedding,train_negative_embedding))\n",
    "X_test_embedding = np.vstack((test_positive_embedding,test_negative_embedding))\n",
    "y_train_full = np.concatenate((train_positive_labels, train_negative_labels), axis = 0)\n",
    "y_test = np.concatenate((test_positive_labels, test_negative_labels), axis = 0)\n",
    "\n",
    "train_positive_pt5 = pd.read_csv(\"data/DeepSuccinylSite/features/full/train_positive_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "train_negative_pt5 = pd.read_csv(\"data/DeepSuccinylSite/features/full/train_negative_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "test_positive_pt5 = pd.read_csv(\"data/DeepSuccinylSite/features/full/test_positive_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "test_negative_pt5 = pd.read_csv(\"data/DeepSuccinylSite/features/full/test_negative_ProtT5-XL-UniRef50.csv\", header = None).iloc[:,2:]\n",
    "\n",
    "# stack positive and negative data together\n",
    "X_train_pt5_full = np.vstack((train_positive_pt5,train_negative_pt5))\n",
    "X_test_pt5 = np.vstack((test_positive_pt5,test_negative_pt5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "7389589c-1d7c-4a57-951d-31beaf477cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle X and y together\n",
    "# X_train_pt5_full, X_train_full_embedding, y_train = shuffle(X_train_pt5_full, X_train_full_embedding, y_train_full)\n",
    "# X_test_pt5, X_test_embedding, y_test = shuffle(X_test_pt5, X_test_embedding, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e641a077",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "# plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a7fbd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Embedding():\n",
    "    # Embedding\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(256, 21, input_length=33))\n",
    "    model.add(Lambda(lambda x: K.expand_dims(x, 3)))\n",
    "    model.add(Conv2D(32, kernel_size=(17, 3), activation = 'relu', kernel_initializer='he_normal', padding = 'VALID'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16, activation='relu', kernel_initializer='he_normal'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855e40f-102c-43d4-a8df-d83fc94c8fbc",
   "metadata": {},
   "source": [
    "### Iterated 10-Fold CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f13cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(10, shuffle=True)\n",
    "\n",
    "# initialize average variables\n",
    "avg_acc, avg_mcc, avg_sp, avg_sn = 0, 0, 0, 0\n",
    "\n",
    "for train, val in kfold.split(X_train_full_embedding, y_train_full):\n",
    "\n",
    "    # Early stopping\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=3, mode='auto')\n",
    "\n",
    "    # Checkpointer\n",
    "    metric = 'val_accuracy'\n",
    "    checkpointer = ModelCheckpoint(filepath=\"models/st_model_best.h5\",\n",
    "                            monitor = metric,\n",
    "                            verbose=0, \n",
    "                            save_weights_only=False,\n",
    "                            save_best_only=True)\n",
    "\n",
    "    model = CNN_Embedding()\n",
    "    model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss=BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    # seperate val data\n",
    "    X_train, X_val = X_train_full_embedding[train], X_train_full_embedding[val]\n",
    "    y_train, y_val = y_train_full[train], y_train_full[val]\n",
    "\n",
    "    # Training and Evaluation\n",
    "    history = model.fit(X_train, y_train, batch_size=256, epochs=100, verbose=1, callbacks=[checkpointer],\n",
    "                            validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_val).reshape(y_val.shape[0],)\n",
    "\n",
    "    y_pred = (y_pred > 0.5)\n",
    "    y_pred = [int(i) for i in y_pred]\n",
    "    y_val = np.array(y_val)\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    mcc = matthews_corrcoef(y_val, y_pred)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    sn = cm[1][1]/(cm[1][1]+cm[1][0])\n",
    "    sp = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    print(acc,mcc,sn,sp)\n",
    "    # plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e2f5e-b67f-41e3-a8cc-13788627d349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
