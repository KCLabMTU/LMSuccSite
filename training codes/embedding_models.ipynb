{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06dcb98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape, Lambda\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.utils import shuffle\n",
    "from keras.layers import Embedding\n",
    "from keras import backend as K\n",
    "from keras.backend import expand_dims\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l1, l2\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "r_test_x = []\n",
    "r_test_y = []\n",
    "posit_1 = 1;\n",
    "negat_0 = 0;\n",
    "win_size = 33 # actual window size\n",
    "win_size_kernel = int(win_size/2 + 1)\n",
    "\n",
    "\n",
    "# define universe of possible input values\n",
    "alphabet = 'ARNDCQEGHILKMFPSTWYV-'\n",
    "\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "\n",
    "# TRAIN DATASET -------------------------------------------------------------\n",
    "#for positive sequence\n",
    "def inner1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    train_x.append(integer_encoded)\n",
    "    train_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"data/positive_sites.fasta\", \"fasta\"): # training data positive\n",
    "    inner1()\n",
    "#for negative sequence\n",
    "def inner2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    train_x.append(integer_encoded)\n",
    "    train_y.append(negat_0)\n",
    "for seq_record in SeqIO.parse(\"data/negative_sites.fasta\", \"fasta\"): # training data negative\n",
    "    inner2()\n",
    "# Changing to array (matrix)    \n",
    "train_x = np.array(train_x)\n",
    "train_y = array(train_y)\n",
    "\n",
    "\n",
    "#-------------------------TEST DATASET----------------------------------------\n",
    "#for positive sequence\n",
    "def innertest1():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #rint(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(posit_1)\n",
    "for seq_record in SeqIO.parse(\"data/test_positive_sites.fasta\", \"fasta\"): # test positive\n",
    "    innertest1()\n",
    "#for negative sequence\n",
    "def innertest2():\n",
    "    #Input\n",
    "    data = seq_record.seq\n",
    "    #print(data) \n",
    "    # integer encode input data\n",
    "    for char in data:\n",
    "        if char not in alphabet:\n",
    "            return\n",
    "    integer_encoded = [char_to_int[char] for char in data]\n",
    "    r_test_x.append(integer_encoded)\n",
    "    r_test_y.append(negat_0)\n",
    "for seq_record in SeqIO.parse(\"data/test_negative_sites.fasta\", \"fasta\"): # test negative\n",
    "    innertest2()\n",
    "# Changing to array (matrix)    \n",
    "r_test_x = array(r_test_x)\n",
    "r_test_y = array(r_test_y)\n",
    "\n",
    "\n",
    "\n",
    "# Balancing test dataset\n",
    "# Testing Data Balancing by undersampling####################################\n",
    "rus = RandomUnderSampler(random_state=7)\n",
    "x_res3, y_res3 = rus.fit_resample(r_test_x, r_test_y)\n",
    "#Shuffling\n",
    "r_test_x, r_test_y = shuffle(x_res3, y_res3, random_state=7)\n",
    "r_test_x = np.array(r_test_x)\n",
    "r_test_y = np.array(r_test_y)\n",
    "############################################################################\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------#\n",
    "#################CNN#####################################\n",
    "epochs = 100\n",
    "num_classes = 2\n",
    "batch_size = 256\n",
    "optimize_2 = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_2 = tf.keras.losses.binary_crossentropy\n",
    "\n",
    "\n",
    "\n",
    "test_size = 0.2\n",
    "seed = 3\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_x, train_y, test_size=test_size,\n",
    "random_state=seed)\n",
    "\n",
    "# Training Data Balancing by undersampling####################################\n",
    "\n",
    "# for idx,a in enumerate(x_train):\n",
    "#     if len(a) != 49:\n",
    "#         print(idx)\n",
    "\n",
    "# import sys\n",
    "# sys.exit(0)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=7)\n",
    "x_res, y_res = rus.fit_resample(x_train, y_train)\n",
    "#Shuffling\n",
    "x_train, y_train = shuffle(x_res, y_res, random_state=7)\n",
    "# x_train = np.array(x_train)\n",
    "# y_train = np.array(y_train)\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "# Testing Data Balancing by undersampling####################################\n",
    "\n",
    "rus = RandomUnderSampler(random_state=7)\n",
    "x_res1, y_res1 = rus.fit_resample(x_test, y_test)\n",
    "#Shuffling\n",
    "x_test, y_test = shuffle(x_res1, y_res1, random_state=7)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "############################################################################\n",
    "\n",
    "train_size = len(x_train)\n",
    "test_size = len(x_test)\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ee8e544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7590, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7c2129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1890, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240098fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 33, 21)\n",
      "(None, 33, 21, 1)\n",
      "(None, 33)\n",
      "This is initial  [ 0.03364919 -0.04127091 -0.0039528   0.03375487  0.01187714  0.01665456\n",
      " -0.04400437 -0.04404823 -0.03666077  0.01602768 -0.01121925 -0.01817731\n",
      "  0.0189432  -0.04930637  0.04545889  0.00178619  0.01389052 -0.02967556\n",
      " -0.03876041  0.03912877 -0.00208048]\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - 6s 180ms/step - loss: 0.8522 - accuracy: 0.4982 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6933 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4996 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5030 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6933 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6933 - accuracy: 0.4904 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6931 - accuracy: 0.5028 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "30/30 [==============================] - 5s 162ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 9/100\n",
      "30/30 [==============================] - 5s 163ms/step - loss: 0.6931 - accuracy: 0.5091 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6933 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4925 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.5016 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6931 - accuracy: 0.5043 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5013 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 16/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6931 - accuracy: 0.5103 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.4978 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.5034 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6930 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 23/100\n",
      "30/30 [==============================] - 5s 162ms/step - loss: 0.6931 - accuracy: 0.5024 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6933 - accuracy: 0.4928 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6929 - accuracy: 0.5198 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6934 - accuracy: 0.4937 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6934 - accuracy: 0.4929 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6931 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6933 - accuracy: 0.4891 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4954 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 34/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 36/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6932 - accuracy: 0.4913 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 37/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.5115 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6931 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.5054 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 42/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5086 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4941 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 44/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4931 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 47/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4979 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6931 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 51/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.5011 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4949 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 54/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4993 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 56/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.5014 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 57/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4959 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4904 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 59/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4888 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 61/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 62/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6931 - accuracy: 0.4995 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 63/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5115 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "30/30 [==============================] - 5s 157ms/step - loss: 0.6932 - accuracy: 0.4991 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 65/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 66/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.5008 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 67/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6932 - accuracy: 0.5037 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 69/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.5104 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 70/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4964 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 72/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 74/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.5029 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 75/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4930 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 77/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.5004 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4859 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 79/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.4992 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 81/100\n",
      "30/30 [==============================] - 5s 157ms/step - loss: 0.6932 - accuracy: 0.4845 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6931 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 85/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5100 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 86/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 87/100\n",
      "30/30 [==============================] - 5s 158ms/step - loss: 0.6932 - accuracy: 0.4933 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.4912 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 89/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.5030 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 90/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4958 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 91/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 92/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.4989 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4966 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.4939 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 95/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 96/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.5007 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6931 - accuracy: 0.4968 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 99/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6931 - accuracy: 0.5099 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "30/30 [==============================] - 5s 159ms/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1a90266e50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(batch_size, 21, input_length=win_size))\n",
    "print(model.output_shape)\n",
    "model.add(Lambda(lambda x: K.expand_dims(x, 3)))\n",
    "print(model.output_shape)\n",
    "model.add(Conv2D(64, kernel_size=(win_size_kernel, 3), activation = 'relu', kernel_initializer='he_normal', padding = 'VALID'))\n",
    "#model.add(BatchNormalization())\n",
    "print(model.input_shape)\n",
    "model.add(Dropout(0.6))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation = 'relu', kernel_initializer='he_normal', padding = 'SAME'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.6))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(256, (3, 3), activation = 'relu', kernel_initializer='he_normal', padding = 'SAME'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(768, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=loss_2,\n",
    "              optimizer=optimize_2,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "metric = 'val_accuracy'\n",
    "checkpointer = ModelCheckpoint(filepath=\"test_model/st_model_best.h5\", \n",
    "                               monitor = metric,\n",
    "                               verbose=0, \n",
    "                               save_weights_only=False,\n",
    "                               save_best_only=True)\n",
    "\n",
    "print(\"This is initial \",model.layers[0].get_weights()[0][16])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=[checkpointer],\n",
    "          validation_data=(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379a2eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 33, 21)\n",
      "(None, 33, 21, 1)\n",
      "(None, 33)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 33, 21)            1344      \n",
      "                                                                 \n",
      " lambda_2 (Lambda)           (None, 33, 21, 1)         0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 17, 21, 64)        1152      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 17, 21, 64)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 17, 21, 128)       24704     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 17, 21, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 10, 128)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 10240)             0         \n",
      "                                                                 \n",
      " dense_1_niraj (Dense)       (None, 128)               1310848   \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2_niraj (Dense)       (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,346,434\n",
      "Trainable params: 1,346,434\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = Sequential()\n",
    "model.add(Embedding(64, 21, input_length=win_size))\n",
    "print(model.output_shape)\n",
    "model.add(Lambda(lambda x: K.expand_dims(x, 3)))\n",
    "print(model.output_shape)\n",
    "model.add(Conv2D(64, kernel_size=(win_size_kernel, 1), activation = 'relu', kernel_initializer='he_normal', padding = 'VALID'))\n",
    "#model.add(BatchNormalization())\n",
    "print(model.input_shape)\n",
    "model.add(Dropout(0.8))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 1), activation = 'relu', kernel_initializer='he_normal', padding = 'SAME'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dropout(0.8))\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Conv2D(256, (3, 3), activation = 'relu', kernel_initializer='he_normal', padding = 'SAME'))\n",
    "#model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_normal', name = 'dense_1_niraj'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='he_normal', name = 'dense_2_niraj'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c8816a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is initial  [ 0.00481473  0.00154876  0.01689338  0.01558162  0.00987921  0.02222928\n",
      " -0.00816543 -0.00516471  0.01736599 -0.00542159 -0.00810777  0.00466594\n",
      " -0.01895982 -0.00466077 -0.00109076 -0.00056426  0.0071848  -0.01140351\n",
      "  0.00243719  0.00672321 -0.02403297]\n",
      "Epoch 1/100\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5001"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to create dataset (name already exists)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m checkpointer \u001b[38;5;241m=\u001b[39m ModelCheckpoint(filepath\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_model/st_model_best_2.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m      9\u001b[0m                                monitor \u001b[38;5;241m=\u001b[39m metric,\n\u001b[1;32m     10\u001b[0m                                verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \n\u001b[1;32m     11\u001b[0m                                save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m                                save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is initial \u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_weights()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m16\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpointer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#Embedding output\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is final \u001b[39m\u001b[38;5;124m\"\u001b[39m,model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_weights()[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m16\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/h5py/_hl/group.py:149\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[0;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[1;32m    146\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    147\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[0;32m--> 149\u001b[0m dsid \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    150\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n",
      "File \u001b[0;32m~/anaconda3/envs/bio/lib/python3.9/site-packages/h5py/_hl/dataset.py:142\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[0;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, allow_unknown_filter)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[0;32m--> 142\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[1;32m    145\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5d.pyx:87\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to create dataset (name already exists)"
     ]
    }
   ],
   "source": [
    "model.compile(loss=loss_2,\n",
    "              optimizer=optimize_2,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=5, mode='auto')\n",
    "\n",
    "metric = 'val_accuracy'\n",
    "checkpointer = ModelCheckpoint(filepath=\"test_model/st_model_best_2.h5\", \n",
    "                               monitor = metric,\n",
    "                               verbose=0, \n",
    "                               save_weights_only=False,\n",
    "                               save_best_only=True)\n",
    "\n",
    "print(\"This is initial \",model.layers[0].get_weights()[0][16])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          callbacks=[checkpointer],\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "#Embedding output\n",
    "print(\"This is final \",model.layers[0].get_weights()[0][16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd5e54d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 21 is out of bounds for axis 0 with size 21",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2722002/3697336087.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 21 is out of bounds for axis 0 with size 21"
     ]
    }
   ],
   "source": [
    "model.layers[0].get_weights()[0][21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca504d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8425922393798828\n",
      "Test accuracy: 0.709486186504364\n",
      "16/16 [==============================] - 0s 21ms/step\n",
      "Matthews Correlation :  0.42458463095540494\n",
      "Confusion Matrix : \n",
      " [[159  94]\n",
      " [ 53 200]]\n",
      "AUC :  0.709486166007905\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.63      0.68       253\n",
      "           1       0.68      0.79      0.73       253\n",
      "\n",
      "    accuracy                           0.71       506\n",
      "   macro avg       0.72      0.71      0.71       506\n",
      "weighted avg       0.72      0.71      0.71       506\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 33, 33)            8448      \n",
      "                                                                 \n",
      " lambda (Lambda)             (None, 33, 33, 1)         0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 17, 31, 64)        3328      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 17, 31, 64)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 17, 31, 128)       73856     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 17, 31, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 8, 15, 128)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 15360)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 768)               11797248  \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 768)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               196864    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12,080,258\n",
      "Trainable params: 12,080,258\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "r_test_y_2 = tf.keras.utils.to_categorical(r_test_y, num_classes)\n",
    "score = model.evaluate(r_test_x, r_test_y_2, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import confusion_matrix\n",
    "Y_pred = model.predict(r_test_x)\n",
    "Y_pred = (Y_pred > 0.5)\n",
    "y_pred1 = [np.argmax(y, axis=None, out=None) for y in Y_pred]\n",
    "y_pred1 = np.array(y_pred1)\n",
    "\n",
    "print(\"Matthews Correlation : \",matthews_corrcoef(r_test_y, y_pred1))\n",
    "print(\"Confusion Matrix : \\n\",confusion_matrix(r_test_y, y_pred1))\n",
    "# ROC\n",
    "\n",
    "fpr, tpr, _ = roc_curve(r_test_y, y_pred1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(\"AUC : \", roc_auc)\n",
    "print(classification_report(r_test_y, y_pred1))\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve for ST')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "print(model.summary())\n",
    "# Save model\n",
    "model.save('models/embedding_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1671b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    # learning curves of model accuracy\n",
    "    plt.plot(history.history['accuracy'], label='train_acc')\n",
    "    plt.plot(history.history['val_accuracy'], label='test_acc')\n",
    "    plt.plot(history.history['loss'], label='train_loss')\n",
    "    plt.plot(history.history['val_loss'], label='test_loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb113bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "plot(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c225af7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
